{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heart Disease Data Preprocessing and Cleaning\n",
        "\n",
        "This notebook covers the initial data preprocessing steps for the Heart Disease UCI dataset including:\n",
        "- Data loading and exploration\n",
        "- Missing value handling\n",
        "- Data encoding for categorical variables\n",
        "- Feature scaling\n",
        "- Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the real Heart Disease UCI dataset",
        "print(\"Loading Heart Disease UCI Dataset...\")",
        "",
        "# Load the dataset",
        "df = pd.read_csv('data/heart_disease_uci.csv')",
        "",
        "print(f\"Original dataset shape: {df.shape}\")",
        "print(f\"Original columns: {list(df.columns)}\")",
        "",
        "# Data preprocessing for the real dataset",
        "print(\"\\nPreprocessing the real dataset...\")",
        "",
        "# Create a copy for preprocessing",
        "df_processed = df.copy()",
        "",
        "# Handle categorical variables",
        "# Convert sex to binary (Male=1, Female=0)",
        "df_processed['sex'] = df_processed['sex'].map({'Male': 1, 'Female': 0})",
        "",
        "# Convert chest pain type to numeric",
        "cp_mapping = {",
        "    'typical angina': 0,",
        "    'atypical angina': 1,",
        "    'non-anginal': 2,",
        "    'asymptomatic': 3",
        "}",
        "df_processed['cp'] = df_processed['cp'].map(cp_mapping)",
        "",
        "# Convert fasting blood sugar to binary",
        "df_processed['fbs'] = df_processed['fbs'].astype(int)",
        "",
        "# Convert resting ECG to numeric",
        "restecg_mapping = {",
        "    'normal': 0,",
        "    'lv hypertrophy': 1,",
        "    'st-t abnormality': 2",
        "}",
        "df_processed['restecg'] = df_processed['restecg'].map(restecg_mapping)",
        "",
        "# Convert exercise induced angina to binary",
        "df_processed['exang'] = df_processed['exang'].astype(int)",
        "",
        "# Convert ST slope to numeric",
        "slope_mapping = {",
        "    'upsloping': 0,",
        "    'flat': 1,",
        "    'downsloping': 2",
        "}",
        "df_processed['slope'] = df_processed['slope'].map(slope_mapping)",
        "",
        "# Convert thalassemia to numeric",
        "thal_mapping = {",
        "    'normal': 1,",
        "    'fixed defect': 2,",
        "    'reversable defect': 3",
        "}",
        "df_processed['thal'] = df_processed['thal'].map(thal_mapping)",
        "",
        "# Use 'num' column as target (0=no disease, >0=disease)",
        "# Convert to binary: 0=no disease, 1=disease",
        "df_processed['target'] = (df_processed['num'] > 0).astype(int)",
        "",
        "# Select relevant features (exclude id, dataset, and target columns)",
        "feature_columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', ",
        "                   'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal']",
        "",
        "# Create final dataset with selected features and target",
        "df_final = df_processed[feature_columns + ['target']].copy()",
        "",
        "# Handle missing values (replace with median for numerical columns)",
        "for col in df_final.columns:",
        "    if df_final[col].dtype in ['int64', 'float64']:",
        "        df_final[col] = df_final[col].fillna(df_final[col].median())",
        "",
        "# Save the processed dataset",
        "df_final.to_csv('data/heart_disease.csv', index=False)",
        "",
        "print(f\"\\nProcessed dataset shape: {df_final.shape}\")",
        "print(f\"Features: {list(df_final.columns[:-1])}\")",
        "print(f\"Target distribution: {df_final['target'].value_counts().to_dict()}\")",
        "print(f\"Missing values: {df_final.isnull().sum().sum()}\")",
        "print(\"\\nReal Heart Disease UCI dataset loaded and preprocessed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('data/heart_disease.csv')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Overview:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing Values Analysis:\")\n",
        "print(\"=\" * 30)\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_values,\n",
        "    'Missing Percentage': missing_percentage\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "# Visualize missing values\n",
        "if missing_values.sum() > 0:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    missing_values[missing_values > 0].plot(kind='bar')\n",
        "    plt.title('Missing Values by Column')\n",
        "    plt.ylabel('Number of Missing Values')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No missing values found in the dataset!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values\n",
        "print(\"Handling Missing Values:\")\n",
        "print(\"=\" * 25)\n",
        "\n",
        "# Create a copy for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# Fill missing values with median for numerical columns\n",
        "numerical_columns = df_processed.select_dtypes(include=[np.number]).columns\n",
        "for col in numerical_columns:\n",
        "    if df_processed[col].isnull().sum() > 0:\n",
        "        median_value = df_processed[col].median()\n",
        "        df_processed[col].fillna(median_value, inplace=True)\n",
        "        print(f\"Filled {col} missing values with median: {median_value}\")\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(f\"\\nMissing values after preprocessing: {df_processed.isnull().sum().sum()}\")\n",
        "\n",
        "# Display the processed dataset info\n",
        "print(\"\\nProcessed Dataset Info:\")\n",
        "print(df_processed.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "print(\"Exploratory Data Analysis:\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "# Target variable distribution\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# 1. Target distribution\n",
        "plt.subplot(2, 3, 1)\n",
        "target_counts = df_processed['target'].value_counts()\n",
        "plt.pie(target_counts.values, labels=['No Heart Disease', 'Heart Disease'], autopct='%1.1f%%')\n",
        "plt.title('Target Variable Distribution')\n",
        "\n",
        "# 2. Age distribution by target\n",
        "plt.subplot(2, 3, 2)\n",
        "df_processed.boxplot(column='age', by='target', ax=plt.gca())\n",
        "plt.title('Age Distribution by Heart Disease')\n",
        "plt.suptitle('')  # Remove default title\n",
        "\n",
        "# 3. Sex distribution by target\n",
        "plt.subplot(2, 3, 3)\n",
        "sex_target = pd.crosstab(df_processed['sex'], df_processed['target'])\n",
        "sex_target.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Sex vs Heart Disease')\n",
        "plt.xticks([0, 1], ['Female', 'Male'], rotation=0)\n",
        "\n",
        "# 4. Chest pain type distribution\n",
        "plt.subplot(2, 3, 4)\n",
        "cp_target = pd.crosstab(df_processed['cp'], df_processed['target'])\n",
        "cp_target.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Chest Pain Type vs Heart Disease')\n",
        "plt.xticks([0, 1, 2, 3], ['Typical', 'Atypical', 'Non-anginal', 'Asymptomatic'], rotation=45)\n",
        "\n",
        "# 5. Blood pressure distribution\n",
        "plt.subplot(2, 3, 5)\n",
        "df_processed.boxplot(column='trestbps', by='target', ax=plt.gca())\n",
        "plt.title('Blood Pressure by Heart Disease')\n",
        "plt.suptitle('')\n",
        "\n",
        "# 6. Cholesterol distribution\n",
        "plt.subplot(2, 3, 6)\n",
        "df_processed.boxplot(column='chol', by='target', ax=plt.gca())\n",
        "plt.title('Cholesterol by Heart Disease')\n",
        "plt.suptitle('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation Analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Correlation heatmap\n",
        "correlation_matrix = df_processed.corr()\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Feature Correlation Heatmap')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print correlation with target variable\n",
        "print(\"Correlation with Target Variable:\")\n",
        "print(\"=\" * 35)\n",
        "target_corr = correlation_matrix['target'].drop('target').sort_values(key=abs, ascending=False)\n",
        "for feature, corr in target_corr.items():\n",
        "    print(f\"{feature:12}: {corr:6.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "print(\"Feature Scaling:\")\n",
        "print(\"=\" * 15)\n",
        "\n",
        "# Separate features and target\n",
        "X = df_processed.drop('target', axis=1)\n",
        "y = df_processed['target']\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to DataFrame for easier handling\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(\"Original features statistics:\")\n",
        "print(X.describe())\n",
        "print(\"\\nScaled features statistics:\")\n",
        "print(X_scaled_df.describe())\n",
        "\n",
        "# Save the preprocessed data\n",
        "X_scaled_df.to_csv('data/X_scaled.csv', index=False)\n",
        "y.to_csv('data/y_target.csv', index=False)\n",
        "\n",
        "print(f\"\\nPreprocessed data saved:\")\n",
        "print(f\"Features shape: {X_scaled_df.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}